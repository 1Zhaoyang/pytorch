{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Pytorch模型训练实用教程（余霆嵩）\n",
    "----\n",
    "<https://github.com/tensor-yu/PyTorch_Tutorial>\n",
    "Chapter4: 监控模型——可视化\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.4 梯度及权值分布可视化**   \n",
    "1. 在网络训练过程中，我们常常会遇到梯度消失、梯度爆炸等问题，我们可以通过记录每个epoch的梯度的值来检测梯度的情况；\n",
    "2. 还可以记录权值，分析权值更新的方向是否符合规律。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"..\")\n",
    "from utils import MyDataset, validate, show_confMat, Net\n",
    "from tensorboardX import SummaryWriter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_txt_path = os.path.join(\"Data\",\"train.txt\")\n",
    "valid_txt_path = os.path.join(\"Data\", \"valid.txt\")\n",
    "classes_name = ['plane','car','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "train_bs = 16\n",
    "valid_bs = 16\n",
    "lr_init = 0.001\n",
    "max_epoch = 3\n",
    "# log\n",
    "log_dir = os.path.join(\"Result\",\"hist_grad_weight\")\n",
    "writer = SummaryWriter(log_dir = log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1/4: 加载数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "norMean = [0.4948052, 0.48568845, 0.44682974]\n",
    "normStd = [0.24580306, 0.24236229, 0.2603115]\n",
    "normTransform = transforms.Normalize(normMean, normStd)\n",
    "trainTransform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    normTransform\n",
    "])\n",
    "validTransform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normTransform\n",
    "])\n",
    "\n",
    "# 构建Dataset实例\n",
    "train_data = MyDataset(txt_path=train_txt_path, transform=trainTransform)\n",
    "valid_data = MyDataset(txt_path=valid_txt_path, transform=validTransform)\n",
    "\n",
    "#构建DataLoder\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=train_bs, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_data, batch_size=valid_bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2/4: 网络初始化**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net() #创建一个网络\n",
    "net.initialize_weights() #初始化权值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3/4: 定义损失函数和优化器**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr_init, momentum=0.9, dampening=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1) # 设置学习率下降策略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4/4: 训练**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(max_epoch):\n",
    "    loss_sigma = 0.0 #记录一个epoch的loss之和\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    \n",
    "    \n",
    "    for i, data in enumerate(train_loader):\n",
    "        # 获取图片和标签\n",
    "        inputs, labels = data\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        # forward, backward, update weights\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        # 统计预测信息\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct =+(predicted == labels).squeeze().sum().numpy()\n",
    "        loss_sigma +=loss.item()\n",
    "        \n",
    "        # 每10个iteration打印一次训练信息，loss为10个iteration的平均\n",
    "        if i% 10 == 9:\n",
    "            loss_avg = loss_sigma/10\n",
    "            loss_sigma = 0.0\n",
    "            print(\"Training:Epoch[{:0>3}/{:0>3}] Iteration[{:0>3}/{:0>3}] Loss:{:.4f} Acc:{:.2%}\".format(\n",
    "            epoch+1, max_epoch, i+1, len(train_loader), loss_avg, correct/total))\n",
    "    scheduler.step() #更新学习率\n",
    "    # 每个epoch，记录梯度，权值\n",
    "    for name, layer in net.named_parameters():\n",
    "        writer.add_histogram(name+ '_grad', layer.grad.cpu().data.numpy(), epoch)\n",
    "        writer.add_histogram(name+ '_data', layer.cpu().data.numpy(), epoch)\n",
    "print('Finished Training')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1: 权值weights的监控**  \n",
    "(1) 卷积层的权值随着训练不断的“扩散”，扩大，一开始是个比较标准的高斯分布，并且最大值不会超过0.3；   \n",
    "(2) 到了后期，权值会发散到0.6+, 这个问题也是需要关注的，若权值太大容易导致过拟合。   \n",
    "(3) 因为模型的输出值会被该特征所主导，从而引起过拟合现象，这个可以通过权值衰减(weight_decay)来缓解。    \n",
    "**2：偏置bias的监控**   \n",
    "(1) 通常会监控输出层的bias的大小，若有特别大的，或者特别小的bias, 那么某一类别的召回率可能会很低。    \n",
    "(2) 可以通过观察输出层的bias来诊断是否在这一环节出问题。   \n",
    "**3: 梯度的监控**   \n",
    "(1) 倘若前面几层的梯度非常小，那么就是梯度流通不畅导致的，可以考虑残差结构或者辅助损失层等trick来解决梯度消失。\n",
    "\n",
    "**文末思考**   \n",
    "(1) 为梯度小的值设置更大的学习率。   \n",
    "(2) 权值大的层，可以考虑设置更大的weight_decay,是否能有效降低该层的权值大小呢？   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
