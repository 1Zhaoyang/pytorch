{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Pytorch模型训练实用教程（余霆嵩）\n",
    "----\n",
    "<https://github.com/tensor-yu/PyTorch_Tutorial>\n",
    "Chapter4: 监控模型——可视化\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils.utils import MyDataset, validate, show_confMat\n",
    "from tensorboardX import SummaryWriter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_txt_path = os.path.join(\"Data\", \"train.txt\")\n",
    "valid_txt_path = os.path.join(\"Data\", \"valid.txt\")\n",
    "classes_name = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "train_bs = 16\n",
    "valid_bs = 16\n",
    "lr_init = 0.001\n",
    "max_epoch = 3\n",
    "\n",
    "# log\n",
    "now_time = datetime.now()\n",
    "time_str = datetime.strftime(now_time, '%m-%d_%H-%M-%S')\n",
    "log_dir = os.path.join(\"Result\", time_str)\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "writer = SummaryWriter(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1/5: 加载数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理设置\n",
    "normMean = [0.4948052, 0.48568845, 0.44682974]\n",
    "normStd = [0.24580306, 0.24236229, 0.2603115]\n",
    "normTransform = transforms.Normalize(normMean, normStd)\n",
    "trainTransform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    normTransform\n",
    "])\n",
    "\n",
    "validTransform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normTransform\n",
    "])\n",
    "\n",
    "# 构建MyDataset实例\n",
    "train_data = MyDataset(txt_path=train_txt_path, transform=trainTransform)\n",
    "valid_data = MyDataset(txt_path=valid_txt_path, transform=validTransform)\n",
    "\n",
    "# 构建DataLoder\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=train_bs, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_data, batch_size=valid_bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2/5: 定义网络**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    # 定义权值初始化\n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                torch.nn.init.xavier_normal_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                torch.nn.init.normal_(m.weight.data, 0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "net = Net()     # 创建一个网络\n",
    "net.initialize_weights()    # 初始化权值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step3/5: 定义损失函数和优化器**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()                                                   # 选择损失函数\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr_init, momentum=0.9, dampening=0.1)    # 选择优化器\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)     # 设置学习率下降策略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4/5: 训练**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(max_epoch):\n",
    "\n",
    "    loss_sigma = 0.0    # 记录一个epoch的loss之和\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    scheduler.step()  # 更新学习率\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # if i == 30 : break\n",
    "        # 获取图片和标签\n",
    "        inputs, labels = data\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # forward, backward, update weights\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 统计预测信息\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).squeeze().sum().numpy()\n",
    "        loss_sigma += loss.item()\n",
    "\n",
    "        # 每10个iteration 打印一次训练信息，loss为10个iteration的平均\n",
    "        if i % 10 == 9:\n",
    "            loss_avg = loss_sigma / 10\n",
    "            loss_sigma = 0.0\n",
    "            print(\"Training: Epoch[{:0>3}/{:0>3}] Iteration[{:0>3}/{:0>3}] Loss: {:.4f} Acc:{:.2%}\".format(\n",
    "                epoch + 1, max_epoch, i + 1, len(train_loader), loss_avg, correct / total))\n",
    "\n",
    "            # 记录训练loss\n",
    "            writer.add_scalars('Loss_group', {'train_loss': loss_avg}, epoch)\n",
    "            # 记录learning rate\n",
    "            writer.add_scalar('learning rate', scheduler.get_lr()[0], epoch)\n",
    "            # 记录Accuracy\n",
    "            writer.add_scalars('Accuracy_group', {'train_acc': correct / total}, epoch)\n",
    "\n",
    "    # 每个epoch，记录梯度，权值\n",
    "    for name, layer in net.named_parameters():\n",
    "        writer.add_histogram(name + '_grad', layer.grad.cpu().data.numpy(), epoch)\n",
    "        writer.add_histogram(name + '_data', layer.cpu().data.numpy(), epoch)\n",
    "\n",
    "    # ------------------------------------ 观察模型在验证集上的表现 ------------------------------------\n",
    "    if epoch % 2 == 0:\n",
    "        loss_sigma = 0.0\n",
    "        cls_num = len(classes_name)\n",
    "        conf_mat = np.zeros([cls_num, cls_num])  # 混淆矩阵\n",
    "        net.eval()\n",
    "        for i, data in enumerate(valid_loader):\n",
    "\n",
    "            # 获取图片和标签\n",
    "            images, labels = data\n",
    "            images, labels = Variable(images), Variable(labels)\n",
    "\n",
    "            # forward\n",
    "            outputs = net(images)\n",
    "            outputs.detach_()\n",
    "\n",
    "            # 计算loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss_sigma += loss.item()\n",
    "\n",
    "            # 统计\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            # labels = labels.data    # Variable --> tensor\n",
    "\n",
    "            # 统计混淆矩阵\n",
    "            for j in range(len(labels)):\n",
    "                cate_i = labels[j].numpy()\n",
    "                pre_i = predicted[j].numpy()\n",
    "                conf_mat[cate_i, pre_i] += 1.0\n",
    "\n",
    "        print('{} set Accuracy:{:.2%}'.format('Valid', conf_mat.trace() / conf_mat.sum()))\n",
    "        # 记录Loss, accuracy\n",
    "        writer.add_scalars('Loss_group', {'valid_loss': loss_sigma / len(valid_loader)}, epoch)\n",
    "        writer.add_scalars('Accuracy_group', {'valid_acc': conf_mat.trace() / conf_mat.sum()}, epoch)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5/5: 保存模型并制作混淆矩阵**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class:plane     , total num:800.0 , correct num:0.0    Recall: 0.00% Precision: 0.00%\n",
      "class:car       , total num:800.0 , correct num:0.0    Recall: 0.00% Precision: 0.00%\n",
      "class:bird      , total num:800.0 , correct num:0.0    Recall: 0.00% Precision: 0.00%\n",
      "class:cat       , total num:800.0 , correct num:625.0  Recall: 78.03% Precision: 10.18%\n",
      "class:deer      , total num:800.0 , correct num:0.0    Recall: 0.00% Precision: 0.00%\n",
      "class:dog       , total num:800.0 , correct num:241.0  Recall: 30.09% Precision: 13.66%\n",
      "class:frog      , total num:800.0 , correct num:0.0    Recall: 0.00% Precision: 0.00%\n",
      "class:horse     , total num:800.0 , correct num:0.0    Recall: 0.00% Precision: 0.00%\n",
      "class:ship      , total num:800.0 , correct num:0.0    Recall: 0.00% Precision: 0.00%\n",
      "class:truck     , total num:800.0 , correct num:28.0   Recall: 3.50% Precision: 27.45%\n",
      "train set Accuracy:11.18%\n",
      "class:plane     , total num:100.0 , correct num:0.0    Recall: 0.00% Precision: 0.00%\n",
      "class:car       , total num:100.0 , correct num:0.0    Recall: 0.00% Precision: 0.00%\n",
      "class:bird      , total num:100.0 , correct num:0.0    Recall: 0.00% Precision: 0.00%\n",
      "class:cat       , total num:100.0 , correct num:80.0   Recall: 79.21% Precision: 10.48%\n",
      "class:deer      , total num:100.0 , correct num:0.0    Recall: 0.00% Precision: 0.00%\n",
      "class:dog       , total num:100.0 , correct num:30.0   Recall: 29.70% Precision: 13.39%\n",
      "class:frog      , total num:100.0 , correct num:0.0    Recall: 0.00% Precision: 0.00%\n",
      "class:horse     , total num:100.0 , correct num:0.0    Recall: 0.00% Precision: 0.00%\n",
      "class:ship      , total num:100.0 , correct num:0.0    Recall: 0.00% Precision: 0.00%\n",
      "class:truck     , total num:100.0 , correct num:2.0    Recall: 1.98% Precision: 12.50%\n",
      "valid set Accuracy:11.20%\n"
     ]
    }
   ],
   "source": [
    "net_save_path = os.path.join(log_dir, 'net_params.pkl')\n",
    "torch.save(net.state_dict(), net_save_path)\n",
    "\n",
    "conf_mat_train, train_acc = validate(net, train_loader, 'train', classes_name)\n",
    "conf_mat_valid, valid_acc = validate(net, valid_loader, 'valid', classes_name)\n",
    "\n",
    "show_confMat(conf_mat_train, classes_name, 'train', log_dir)\n",
    "show_confMat(conf_mat_valid, classes_name, 'valid', log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[1] cd C:\\Users\\pangz\\Pt-PyTorch\\Result   \n",
    "[2] tensorboard --logdir=04-17_00-56-40 --port=6010**   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
